{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Medical Note OCR Pipeline (TrOCR)\n",
    "\n",
    "This notebook demonstrates a high-accuracy pipeline for OCR of handwritten medical notes.\n",
    "\n",
    "**Features:**\n",
    "1. **EasyOCR**: Detection of text bounding boxes.\n",
    "2. **Microsoft TrOCR**: Transformer-based recognition of handwritten text.\n",
    "3. **Preprocessing**: Otsu's thresholding, deskewing, and noise reduction.\n",
    "4. **Structure**: Automatic line grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install easyocr opencv-python matplotlib numpy transformers torch torchvision pillow sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class HandwrittenOCR:\n",
    "    \"\"\"\n",
    "    A robust, object-oriented pipeline for OCR of Handwritten Medical Notes.\n",
    "    Uses EasyOCR for text detection and Microsoft TrOCR for recognition.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize:\n",
    "        1. EasyOCR Reader (Detection only).\n",
    "        2. Microsoft TrOCR (Recognition).\n",
    "        \"\"\"\n",
    "        print(\"Initializing EasyOCR (for detection)...\")\n",
    "        # Initialize EasyOCR just for detection\n",
    "        self.reader = easyocr.Reader(['en'], gpu=True)\n",
    "        \n",
    "        print(\"Initializing Microsoft TrOCR (for recognition)...\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load TrOCR model and processor\n",
    "        self.processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten').to(self.device)\n",
    "        \n",
    "        print(\"Initialization complete.\")\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Load and preprocess the image:\n",
    "        1. Grayscale\n",
    "        2. Gaussian Blur\n",
    "        3. Otsu's Thresholding\n",
    "        4. Deskewing\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file.\n",
    "            \n",
    "        Returns:\n",
    "            np.array: The preprocessed image.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # 1. Convert to Grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 2. Gaussian Blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        # 3. Otsu's Thresholding to binarize\n",
    "        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # 4. Deskewing Logic (on inverted binary)\n",
    "        _, thresh_inv = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        coords = np.column_stack(np.where(thresh_inv > 0))\n",
    "        angle = cv2.minAreaRect(coords)[-1]\n",
    "        \n",
    "        # Adjust angle format\n",
    "        if angle < -45:\n",
    "            angle = -(90 + angle)\n",
    "        else:\n",
    "            angle = -angle\n",
    "            \n",
    "        # Rotate if angle is significant\n",
    "        if abs(angle) > 0.5:\n",
    "            (h, w) = img.shape[:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            img_rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "            print(f\"Deskewed image by {angle:.2f} degrees.\")\n",
    "            return img_rotated\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def recognize_trocr(self, img_crop):\n",
    "        \"\"\"\n",
    "        Use TrOCR to recognize text from a cropped image segment.\n",
    "        \"\"\"\n",
    "        # Convert CV2 (BGR) to PIL (RGB)\n",
    "        img_rgb = cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(img_rgb).convert(\"RGB\")\n",
    "        \n",
    "        # Prepare input\n",
    "        pixel_values = self.processor(images=pil_image, return_tensors=\"pt\").pixel_values.to(self.device)\n",
    "        \n",
    "        # Generate text\n",
    "        generated_ids = self.model.generate(pixel_values, max_new_tokens=20) \n",
    "        generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        return generated_text\n",
    "\n",
    "    def sort_by_line(self, ocr_results, y_threshold=20):\n",
    "        \"\"\"\n",
    "        Sort OCR results into lines based on Y-coordinates.\n",
    "        Results are sorted top-to-bottom, then left-to-right.\n",
    "        \"\"\"\n",
    "        if not ocr_results:\n",
    "            return []\n",
    "            \n",
    "        # Initial sort by Top-Left Y\n",
    "        ocr_results.sort(key=lambda x: x[0][0][1])\n",
    "        \n",
    "        lines = []\n",
    "        current_line = [ocr_results[0]]\n",
    "        \n",
    "        for i in range(1, len(ocr_results)):\n",
    "            bbox = ocr_results[i][0]\n",
    "            prev_bbox = current_line[-1][0]\n",
    "            \n",
    "            y_curr = bbox[0][1]\n",
    "            y_prev = prev_bbox[0][1]\n",
    "            \n",
    "            # If close in Y, same line\n",
    "            if abs(y_curr - y_prev) < y_threshold:\n",
    "                current_line.append(ocr_results[i])\n",
    "            else:\n",
    "                # New line, sort previous line by X and add\n",
    "                current_line.sort(key=lambda x: x[0][0][0])\n",
    "                lines.extend(current_line)\n",
    "                current_line = [ocr_results[i]]\n",
    "        \n",
    "        # Add last line\n",
    "        current_line.sort(key=lambda x: x[0][0][0])\n",
    "        lines.extend(current_line)\n",
    "        \n",
    "        return lines\n",
    "\n",
    "    def extract_text_with_boxes(self, img):\n",
    "        \"\"\"\n",
    "        Run Detection (EasyOCR) + Recognition (TrOCR).\n",
    "        \"\"\"\n",
    "        print(\"Detecting text boxes...\")\n",
    "        detection_results = self.reader.readtext(img)\n",
    "        \n",
    "        final_results = []\n",
    "        print(f\"Found {len(detection_results)} text segments. Recognizing with TrOCR...\")\n",
    "        \n",
    "        for i, (bbox, _, conf) in enumerate(detection_results):\n",
    "            # Crop the image at the bounding box\n",
    "            np_box = np.array(bbox)\n",
    "            min_x = int(np.min(np_box[:, 0]))\n",
    "            max_x = int(np.max(np_box[:, 0]))\n",
    "            min_y = int(np.min(np_box[:, 1]))\n",
    "            max_y = int(np.max(np_box[:, 1]))\n",
    "            \n",
    "            # Clip to image bounds\n",
    "            h, w = img.shape[:2]\n",
    "            min_x = max(0, min_x)\n",
    "            min_y = max(0, min_y)\n",
    "            max_x = min(w, max_x)\n",
    "            max_y = min(h, max_y)\n",
    "            \n",
    "            if max_x - min_x < 5 or max_y - min_y < 5:\n",
    "                continue \n",
    "                \n",
    "            crop = img[min_y:max_y, min_x:max_x]\n",
    "            \n",
    "            try:\n",
    "                text = self.recognize_trocr(crop)\n",
    "                final_results.append((bbox, text, conf))\n",
    "            except Exception as e:\n",
    "                print(f\"TrOCR Error on segment {i}: {e}\")\n",
    "                \n",
    "        # Post-process: Sort by line\n",
    "        sorted_results = self.sort_by_line(final_results)\n",
    "            \n",
    "        return sorted_results\n",
    "\n",
    "    def get_annotated_image(self, original_img, ocr_results):\n",
    "        \"\"\"\n",
    "        Draw bounding boxes and text on the image and return it.\n",
    "        \"\"\"\n",
    "        annotated_img = original_img.copy()\n",
    "        \n",
    "        for (bbox, text, conf) in ocr_results:\n",
    "            pts = np.array(bbox, np.int32)\n",
    "            pts = pts.reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_img, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "            \n",
    "            # Put text (using first point of bbox)\n",
    "            cv2.putText(annotated_img, text, (pts[0][0][0], pts[0][0][1] - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        return annotated_img\n",
    "\n",
    "    def display_results(self, original_img, ocr_results):\n",
    "        annotated_img = self.get_annotated_image(original_img, ocr_results)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Original Pre-processed\")\n",
    "        plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Annotated TrOCR Output\")\n",
    "        plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    ocr = HandwrittenOCR()\n",
    "    \n",
    "    # Set your image path here\n",
    "    sample_image = \"sample_doctor_note.jpg\" \n",
    "    \n",
    "    # Attempt to find an uploaded image if sample doesn't exist\n",
    "    if not os.path.exists(sample_image):\n",
    "        files = [f for f in os.listdir('.') if f.startswith('uploaded_')]\n",
    "        if files:\n",
    "            sample_image = files[0]\n",
    "    \n",
    "    if os.path.exists(sample_image):\n",
    "        print(f\"Processing {sample_image}...\")\n",
    "        processed_img = ocr.preprocess_image(sample_image)\n",
    "        results = ocr.extract_text_with_boxes(processed_img)\n",
    "        \n",
    "        print(\"\\nExtracted Text:\")\n",
    "        for _, text, conf in results:\n",
    "            print(f\"- {text}\")\n",
    "            \n",
    "        ocr.display_results(processed_img, results)\n",
    "    else:\n",
    "        print(\"No image found to process.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
